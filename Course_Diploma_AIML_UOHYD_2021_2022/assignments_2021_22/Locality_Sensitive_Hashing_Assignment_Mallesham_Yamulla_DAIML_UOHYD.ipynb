{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHZYvJL4hQp"
      },
      "source": [
        "# Importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivLpZtEM4sls"
      },
      "source": [
        "# Loading data\n",
        "df_text_raw = pd.read_csv('https://raw.githubusercontent.com/myamullaciencia/open_into_datos/master/lsh_assignment_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVaBmoDk4wbH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3728a5f0-bc5f-47c3-eebb-5b381f4568aa"
      },
      "source": [
        "# view the first 5 observations of a dataframe\n",
        "df_text_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaQrWExk40Sf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dffe6d4-fc05-44dc-f5ba-c06550cb56f0"
      },
      "source": [
        "# Counts per each category\n",
        "df_text_raw['category'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            509\n",
              "business         508\n",
              "politics         415\n",
              "tech             399\n",
              "entertainment    384\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5WT0ukQ5TAy"
      },
      "source": [
        "# Creating training and testing datasets\n",
        "train_text_data = df_text_raw.iloc[:-10,:]\n",
        "test_text_data = df_text_raw.iloc[-10:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg6R02Nk5asI",
        "outputId": "c8d417c1-209c-4920-d4bd-c6931e680b3a"
      },
      "source": [
        "print(f'The training dataset contains row and cols as: {train_text_data.shape} \\nand The testing dataset contains rows and cols as: {test_text_data.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training dataset contains row and cols as: (2215, 2) \n",
            "and The testing dataset contains rows and cols as: (10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN6nvHu36oUF"
      },
      "source": [
        "# create a TFIDF vectorizer with the recommended options\n",
        "text_vectorizer = TfidfVectorizer(ngram_range=(2,3),max_features=4000,min_df=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fxFGM-fO33E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cba3988-5bc4-44c7-acbc-a4cfe58c6ed8"
      },
      "source": [
        "print(f'The TFIDF Vectorizer as: \\n{text_vectorizer}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The TFIDF Vectorizer as: \n",
            "TfidfVectorizer(max_features=4000, min_df=10, ngram_range=(2, 3))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxoK24h369Tu"
      },
      "source": [
        "# fitting vectorizer on train data\n",
        "my_text_model_fit = text_vectorizer.fit(train_text_data['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z_NYLRyYOtt"
      },
      "source": [
        "# transforming train and test text features\n",
        "my_text_features= my_text_model_fit.transform(train_text_data['text'])\n",
        "my_text_features_test = my_text_model_fit.transform(test_text_data['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSfUrTVQJLMa"
      },
      "source": [
        "print(f'TF-IDFs as: \\n{my_text_features.toarray()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2vQ3HmsmgGp"
      },
      "source": [
        "def generate_hyperplanes(n,tot):\n",
        "    \"\"\" Custom function to generate required hyperplanes \"\"\"\n",
        "    np.random.seed(0)\n",
        "    hyper_array=[]\n",
        "    for _ in range(0,n):\n",
        "        hyper_array.append(np.random.normal(0,1,tot))\n",
        "    return np.array(hyper_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoOLYqtcm_C9"
      },
      "source": [
        "# Creating five hyperplanes\n",
        "hypers = generate_hyperplanes(5,my_text_features.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tUAOWgrZ1aY"
      },
      "source": [
        "def wt_trans_x(sparse_mat,hyper_array):\n",
        "    \"\"\" Custom function to caluclate W_Trans_X \"\"\"\n",
        "    trans_list = list()\n",
        "    for fet in sparse_mat:\n",
        "        trans_list.append(fet.dot(hyper_array.T).tolist()[0])\n",
        "    return trans_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_2vawmXIIqC"
      },
      "source": [
        "def hash_key(vector):\n",
        "    \"\"\"Generate a hashkey tupple with 1's and 0's\"\"\"\n",
        "    key = tuple(map(lambda x: 1 if x>0 else 0,vector))\n",
        "    return key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoNECaDUnmMi"
      },
      "source": [
        "def create_hash_key(vec):\n",
        "    \"\"\"create WtansX and generate hashkey on it\"\"\"\n",
        "    wt_x_vec= wt_trans_x(vec,hypers)\n",
        "    hk = hash_key(wt_x_vec[0])\n",
        "    return hk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj_1tn-ta6nq"
      },
      "source": [
        "def create_hash_table(arr):\n",
        "    \"\"\"Generate a hashtable\"\"\"\n",
        "    my_hash_table=dict()\n",
        "    for idx,vec in enumerate(arr):\n",
        "        key_gen=hash_key(vec)\n",
        "        if key_gen not in my_hash_table.keys():\n",
        "            my_hash_table[key_gen]=0\n",
        "        my_hash_table[key_gen]=[]\n",
        "\n",
        "    for idx,vec in enumerate(arr):\n",
        "        key_gen=hash_key(vec)\n",
        "        if key_gen in my_hash_table.keys():\n",
        "            my_hash_table[key_gen].append(idx)\n",
        "    return my_hash_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6v2aSAVYq5g"
      },
      "source": [
        "# Caluclating W_trans_X on training features and creating a hashtable on it\n",
        "x_train = wt_trans_x(my_text_features,hypers)\n",
        "x_train_hast_table = create_hash_table(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3wydVOY5THt"
      },
      "source": [
        "def pred_nearest_neighbor_lsh_labels(train_data,train_features,test_features,x_hash_table,num_of_nbrs):\n",
        "\n",
        "    \"\"\"Custom function to caluclate cosine similarities, find the required NNBs labels for the given train and test datasets\"\"\"\n",
        "    #list to store indices of the required NNB's\n",
        "    label_idx=list()\n",
        "    # a dict to store the counted predicted labels using the indices\n",
        "    label_pred_dict=dict()\n",
        "    # a list to store the finalized predicted label\n",
        "    pred_labels=list()\n",
        "\n",
        "    for fet in test_features:\n",
        "        key_gen = create_hash_key(fet)\n",
        "        neighbours_x = x_hash_table[key_gen]\n",
        "        neighbours_x_arr = np.array(neighbours_x)\n",
        "        cosine_similarities=[]\n",
        "        for nbr in neighbours_x_arr:\n",
        "            cos_sim=np.dot(train_features[nbr],fet.T).todense().item()/(norm(train_features[nbr].toarray())*norm(fet.T.toarray()))\n",
        "            cosine_similarities.append(cos_sim)\n",
        "        n_11_neighbors=neighbours_x_arr[np.argsort(cosine_similarities)[::-1][:num_of_nbrs]]\n",
        "        label_idx.append(n_11_neighbors)\n",
        "\n",
        "    for idx,item in enumerate(label_idx):\n",
        "        label_pred_dict[idx]=Counter(list(train_data.iloc[item,0]))\n",
        "\n",
        "    for labels in label_pred_dict.values():\n",
        "        pred_labels.append(max(labels,key=lambda x:labels[x]))\n",
        "\n",
        "    return pred_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcYFF3038Bg0"
      },
      "source": [
        "# predicting labels of test data by providing training data text features\n",
        "my_pred_labels = pred_nearest_neighbor_lsh_labels(train_text_data,my_text_features,my_text_features_test,x_train_hast_table,11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llTAAN0qmha7"
      },
      "source": [
        "my_pred_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKZDfdQ4quzw",
        "outputId": "a31d8cb1-b86e-41ac-d1ca-cd289797d48d"
      },
      "source": [
        "###########################################\n",
        "## GRADER CELL: Do NOT Change this.\n",
        "# This cell will print \"Success\" if your implmentation of the predictLabels() is correct and the accuracy obtained is above 80%.\n",
        "# Else, it will print \"Failed\"\n",
        "###########################################\n",
        "\n",
        "\n",
        "# custom array to store the predicted labels\n",
        "Y_custom = np.array(my_pred_labels)\n",
        "\n",
        "# Reference grader array - DO NOT MODIFY IT\n",
        "Y_grader = np.array(['tech', 'entertainment', 'tech', 'sport', 'business', 'business', 'politics', 'entertainment', 'politics', 'sport'])\n",
        "\n",
        "# Calculating accuracy by comparing Y_grader and Y_custom\n",
        "accuracy = np.sum(Y_grader==Y_custom) * 10\n",
        "\n",
        "if accuracy >= 80:\n",
        "  print(\"******** Success ********\",\"Accuracy Achieved = \", accuracy,'%')\n",
        "else:\n",
        "  print(\"####### Failed #######\",\"Accuracy Achieved = \", accuracy,'%')\n",
        "  print(\"\\nY_grader = \\n\\n\", Y_grader)\n",
        "  print(\"\\n\",\"*\"*50)\n",
        "  print(\"\\nY_custom = \\n\\n\", Y_custom)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******** Success ******** Accuracy Achieved =  90 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M12sIHiTHS9t",
        "outputId": "738d8683-dc11-4ce7-b88f-6e87c10259bf"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = HashingVectorizer(n_features=2**4)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4tinAzRHUnk",
        "outputId": "0b85382d-2dd3-4145-ef3c-f51a34002ea8"
      },
      "source": [
        "print(X[[1]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t-0.8164965809277261\n",
            "  (0, 11)\t0.4082482904638631\n",
            "  (0, 13)\t0.4082482904638631\n",
            "  (0, 14)\t0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TFpDGM_HjDM"
      },
      "source": [
        "for item in X:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}